<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Reverse TTS</title>
</head>

<body>
  <h1>Reverse TTS ğŸ˜‚</h1>
  <p>Try also ä¸€å¾—é˜æ‹‰ç±³ and é˜¿ç±³è¯ºé˜¿æ–¯</p>
  <p>Thanks for stackoverflow</p>
  <input type="text" id="text" value="ä¸€æŠŠçŸ³æ‰‹">
  <button id="button">Try it</button>
  <hr>
  <span>Playback volume gain</span>
  <input type="number" id="vg" value="50">
</body>
<script>
  document.getElementById("button").onclick = function (event) {
    const text = document.getElementById("text").value;
    (async () => {
      const blob = await new Promise(async resolve => {
        console.log("picking system audio");
        const stream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: true });
        const track = stream.getAudioTracks()[0];
        if (!track)
          throw "System audio not available";

        stream.getVideoTracks().forEach(track => track.stop());

        const mediaStream = new MediaStream();
        mediaStream.addTrack(track);

        const chunks = [];
        const mediaRecorder = new MediaRecorder(mediaStream, { bitsPerSecond: 128000 });
        mediaRecorder.ondataavailable = event => {
          if (event.data.size > 0)
            chunks.push(event.data);
        }
        mediaRecorder.onstop = () => {
          stream.getTracks().forEach(track => track.stop());
          mediaStream.removeTrack(track);
          chunks.reverse();
          resolve(new Blob(chunks));
        }
        mediaRecorder.start();

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.onend = () => mediaRecorder.stop();
        window.speechSynthesis.speak(utterance);
        console.log("speaking...");
      });
      console.log("audio available", blob);

      const audioContext = new AudioContext();
      const arrayBuffer = await blob.arrayBuffer();
      audioContext.decodeAudioData(arrayBuffer, function (buffer) {
        const source = audioContext.createBufferSource();
        console.log(buffer);
        console.log(source);
        Array.prototype.reverse.call(buffer.getChannelData(0));
        source.buffer = buffer;

        let gainNode = audioContext.createGain()
        gainNode.gain.value = parseFloat(document.getElementById("vg").value)
        gainNode.connect(audioContext.destination)

        source.connect(gainNode);
        source.start();
      })

      // const player = new Audio();
      // player.src = URL.createObjectURL(blob);
      // player.autoplay = true;
      // player.controls = true;

    })()
  }
</script>

</html>