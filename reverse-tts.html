<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Reverse TTS</title>
</head>

<body>
  <h1>Reverse TTS 😂</h1>
  <p>Try also 一得阁拉米 and 阿米诺阿斯</p>
  <p>Most code are from stackoverflow</p>
  <input type="text" id="text" value="一把石手">
  <button id="button">Try it</button>
  <hr>
  <span>Playback volume gain</span>
  <input type="number" id="vg" value="5">
  <hr>
  <span>Playback rate</span>
  <input type="number" id="pbr" value="0.75">
</body>
<script>
  let mediaRecorder = null;
  let chunks = [];
  let resolvef = null;
  (async () => {
    console.log("picking system audio");
    const stream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: true });
    const track = stream.getAudioTracks()[0];
    if (!track)
      throw "System audio not available";

    stream.getVideoTracks().forEach(track => track.stop());

    const mediaStream = new MediaStream();
    mediaStream.addTrack(track);

    mediaRecorder = new MediaRecorder(mediaStream, { bitsPerSecond: 128000 });
    mediaRecorder.ondataavailable = event => {
      if (event.data.size > 0)
        chunks.push(event.data);
    }
    mediaRecorder.onstop = () => {
      // stream.getTracks().forEach(track => track.stop());
      // mediaStream.removeTrack(track);
      chunks.reverse();
      resolvef(new Blob(chunks));
    }
  })()
  document.getElementById("button").onclick = function (event) {
    chunks = [];
    const text = document.getElementById("text").value;
    (async () => {
      const blob = await new Promise(async resolve => {
        resolvef = resolve;
        mediaRecorder.start();

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.onend = () => mediaRecorder.stop();
        window.speechSynthesis.speak(utterance);
        console.log("speaking...");
      });
      console.log("audio available", blob);

      const audioContext = new AudioContext();
      const arrayBuffer = await blob.arrayBuffer();
      audioContext.decodeAudioData(arrayBuffer, function (buffer) {
        const source = audioContext.createBufferSource();
        console.log(buffer);
        console.log(source);
        Array.prototype.reverse.call(buffer.getChannelData(0));
        source.buffer = buffer;
        source.playbackRate.value = parseFloat(document.getElementById("pbr").value);

        let gainNode = audioContext.createGain();
        gainNode.gain.value = parseFloat(document.getElementById("vg").value);
        gainNode.connect(audioContext.destination);

        source.connect(gainNode);
        source.start();
      })
    })()
  }
</script>

</html>